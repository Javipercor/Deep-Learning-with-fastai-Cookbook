{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model on a standalone tabular dataset\n",
    "Example of making a standalone dataset available for training a fastai deep learning application.\n",
    "\n",
    "In this notebook we'll go through the steps to train a model on the Kuala Lumpur property dataset: https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for notebook boilerplate\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "from fastbook import *\n",
    "from fastai.tabular.all import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for this notebook\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the notebook for fast.ai\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest the dataset\n",
    "\n",
    "The following cells assume that you have completed the following steps:\n",
    "- Download data_kaggle.csv.zip from https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur\n",
    "- Unzip the downloaded file to extract data_kaggle.csv\n",
    "- In your Gradient environment, create the folder /storage/archive/kl_property\n",
    "- Upload data_kaggle.csv to /storage/archive/kl_property\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a target path for this house price dataset\n",
    "path = URLs.path('kl_property')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest the dataset into a Pandas dataframe\n",
    "df_train = pd.read_csv(path/'data_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Car Parks</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Furnishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KLCC, Kuala Lumpur</td>\n",
       "      <td>RM 1,250,000</td>\n",
       "      <td>2+1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Serviced Residence</td>\n",
       "      <td>Built-up : 1,335 sq. ft.</td>\n",
       "      <td>Fully Furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Damansara Heights, Kuala Lumpur</td>\n",
       "      <td>RM 6,800,000</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bungalow</td>\n",
       "      <td>Land area : 6900 sq. ft.</td>\n",
       "      <td>Partly Furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dutamas, Kuala Lumpur</td>\n",
       "      <td>RM 1,030,000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Condominium (Corner)</td>\n",
       "      <td>Built-up : 1,875 sq. ft.</td>\n",
       "      <td>Partly Furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheras, Kuala Lumpur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bukit Jalil, Kuala Lumpur</td>\n",
       "      <td>RM 900,000</td>\n",
       "      <td>4+1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Condominium (Corner)</td>\n",
       "      <td>Built-up : 1,513 sq. ft.</td>\n",
       "      <td>Partly Furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Location         Price Rooms  Bathrooms  Car Parks  \\\n",
       "0               KLCC, Kuala Lumpur  RM 1,250,000   2+1        3.0        2.0   \n",
       "1  Damansara Heights, Kuala Lumpur  RM 6,800,000     6        7.0        NaN   \n",
       "2            Dutamas, Kuala Lumpur  RM 1,030,000     3        4.0        2.0   \n",
       "3             Cheras, Kuala Lumpur           NaN   NaN        NaN        NaN   \n",
       "4        Bukit Jalil, Kuala Lumpur    RM 900,000   4+1        3.0        2.0   \n",
       "\n",
       "          Property Type                      Size        Furnishing  \n",
       "0    Serviced Residence  Built-up : 1,335 sq. ft.   Fully Furnished  \n",
       "1              Bungalow  Land area : 6900 sq. ft.  Partly Furnished  \n",
       "2  Condominium (Corner)  Built-up : 1,875 sq. ft.  Partly Furnished  \n",
       "3                   NaN                       NaN               NaN  \n",
       "4  Condominium (Corner)  Built-up : 1,513 sq. ft.  Partly Furnished  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53883, 8)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control whether the dependent variable is continuous or categorical\n",
    "# if this switch is set to True then the values in the Price column are replaced with \n",
    "# string indicators: 0 if Price is less or equal to average; 1 if Price is above average\n",
    "categorical_target = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing to clean up the dataset\n",
    "Unlike some other datasets featured on Kaggle, this dataset has many interesting anomalies that need to be cleaned up before fastai data preparations can be appplied to it. In particular, the Size column has values that were entered free form, which means that it needs a lot of work. For this column we've added processing to get a useful numerical value from the columns values where it's possible, but for values that are difficult to parse, we drop the row. We lose about 1% of the rows in this way - a reasonable tradeoff to make to keep the cleanup code as simple as possible.\n",
    "\n",
    "Here are the issues that need to be corrected with this dataset:\n",
    "- Price column has some misisng values. We need to remove these values\n",
    "- Price column includes the ringgit symbol (the symbol for the Malaysian currency). We need to remove this symbol so that this column can be treated as a continuous column\n",
    "- Size column needs to be split to into columns, one with the size type and the other with size (area)\n",
    "- Size (area) column needs to update to remove the measure (\"sq. ft.\") and to convert area vectors into scalars\n",
    "- deal with Size entries like: \"5700 sf sq. ft.\", \"646sf~1001sf sq. ft.\" - remove the rows with ranges or constructs like \"22&#8217;x100&#8217; sq. ft.\", as well as rows that contain strings that cannot be converted into numerics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove the currency symbol\n",
    "def remove_currency(currency_string, input_string):\n",
    "    output_string = re.sub(currency_string,'',input_string)\n",
    "    return(output_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove everything after the space in a string\n",
    "def remove_after_space(input_string):\n",
    "    # remove leading and trailing spaces\n",
    "    input_string = input_string.strip()\n",
    "    #print('input:', input_string)\n",
    "    # remove everything after internal spaces\n",
    "    output_string = re.sub(r'\\s* .*', '', input_string)\n",
    "    output_string = re.sub(r'\\([^)]*\\)','',output_string)\n",
    "    #print('output:',output_string)\n",
    "    return(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing Price values\n",
    "df_train.dropna(subset=['Price'], inplace=True)\n",
    "# remove currency symbol from remaining rows\n",
    "df_train['Price'] = df_train['Price'].apply(lambda x: remove_currency(\"RM \",x))\n",
    "\n",
    "\n",
    "# convert Price column to float\n",
    "df_train['Price'] = pd.to_numeric(df_train['Price'].str.replace(',',''), errors='coerce')\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase values in the Size column\n",
    "df_train['Size'] = df_train['Size'].str.lower()\n",
    "#  remove remaining records that have \"sf\",\"acres\", or \"#\" in the Size column\n",
    "\n",
    "df_train = df_train[~df_train.Size.str.contains(\"sf\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"acre\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"#\",na=False)]\n",
    "\n",
    "# split the Size column into two columns and make the remaining Size column numeric\n",
    "df_train[['Size_type','Size']] = df_train['Size'].str.split(':',expand=True)\n",
    "df_train = df_train[~df_train.Size.str.contains(\"kuala\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"malaysia\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"nil\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"corner\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"unknown\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"n/a\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"na\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"wp\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"xx\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"intermediate\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"wilayah\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"-\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains(\"\\+\",na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains('\\'',na=False)]\n",
    "df_train = df_train[~df_train.Size.str.contains('\\~',na=False)]\n",
    "# remove commas and metric, and convert \"x\" with \"*\" so \"22x80\" becomes \"22*80\" and can yield a scalar when eval() is applied\n",
    "# df_train['Size'] = pd.to_numeric(df_train['Size'].str.replace(',','').str.replace(' sq. ft.','').str.replace(\"x\",\"*\"), errors='coerce')\n",
    "\n",
    "df_train['Size'] = df_train['Size'].str.replace(',','').str.replace('`','').str.replace('@','x').str.replace('\\+ sq. ft.','')\n",
    "#\n",
    "df_train['Size'] = df_train['Size'].str.replace(' sq. ft.','').str.replace('sf sq. ft.','').str.replace('ft','').str.replace('sq','').str.replace(\"xx\",\"*\").str.replace(\"x \",\"*\").str.replace(\" x\",\"*\").str.replace(\"x\",\"*\").str.replace(\"X\",\"*\").replace('\\'','')\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in the Size column\n",
    "df_train['Size'] = df_train['Size'].fillna(\"0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates of the form \"2850 38x25\" by removing everything after space in Size field\n",
    "df_train['Size'] = df_train['Size'].apply(lambda x: remove_after_space(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply eval() to the Size column to convert \"24 x 12\" values to numeric values\n",
    "df_train['Size'] = df_train['Size'].apply(lambda x: eval(str(x)))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a count by column of missing values\n",
    "count = df_train.isna().sum()\n",
    "df_train_missing = (pd.concat([count.rename('missing_count'),\n",
    "                     count.div(len(df_train))\n",
    "                          .rename('missing_ratio')],axis = 1)\n",
    "             .loc[count.ne(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_missing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the target\n",
    "Adjust the Price column for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to replace target values with value indicating whether the input is over or under the mean\n",
    "# note that setting the target to be a string like this results in much higher accuracy (94%) vs. setting\n",
    "# the target to be a float (accuracy ~ 76%)\n",
    "def under_over(x,mean_x):\n",
    "    if (x <= mean_x):\n",
    "        #returner = 0.0\n",
    "        returner = \"0\"\n",
    "    else:\n",
    "        returner = \"1\"\n",
    "    return(returner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target column\n",
    "mean_sp = int(df_train['Price'].mean())\n",
    "if categorical_target:\n",
    "    df_train['Price'] = df_train['Price'].apply(lambda x: under_over(x,mean_sp))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the proportion of Price values\n",
    "df_train['Price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the target, continuous and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms to apply to the tabular dataset\n",
    "procs = [FillMissing,Categorify]\n",
    "# define the dependent variable (y value)\n",
    "dep_var = 'Price'\n",
    "# define columns that are continuous / categorical\n",
    "cont,cat = cont_cat_split(df_train, 1, dep_var=dep_var) \n",
    "print(\"continuous columns are: \",cont)\n",
    "print(\"categorical columns are: \",cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define TabularDataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define TabularDataLoaders object using the dataframe, the list of pre-processing steps, the categorical and continuous\n",
    "# column lists\n",
    "# valid_idx: the indices to use for the validation set\n",
    "procs = [FillMissing,Categorify, Normalize]\n",
    "dls = TabularDataLoaders.from_df(df_train,path,procs= procs, \n",
    "                               cat_names= cat, cont_names = cont, y_names = dep_var, valid_idx=list(range((df_train.shape[0]-5000),df_train.shape[0])), bs=64)\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a sample batch\n",
    "dls.valid.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit the model\n",
    "learn = tabular_learner(dls, metrics=accuracy)\n",
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the loss function used by the learner\n",
    "learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a set of results from the model\n",
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the structure of the trained model structure\n",
    "\n",
    "Use the summary() function to see the structure of the trained model, including:\n",
    "\n",
    "- the layers that make up the model\n",
    "- total parameters\n",
    "- loss function\n",
    "- optimizer function\n",
    "- callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
